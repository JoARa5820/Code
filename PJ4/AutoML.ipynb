{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 0. 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 라이브러리 호출 #####\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터프레임 출력 옵션\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "#지수표현\n",
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 1. 입력값 기입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder : 원본데이터 위치(폴더명)\n",
    "# save_folder : 결과 저장 위치(폴더명)\n",
    "# file_nm : 파일명\n",
    "# target : target 컬럼들 (하나의 'target'명으로 병합할 순서대로, 컬럼명을 리스트 형식으로 기입)\n",
    "# y_colnm : y 컬럼명\n",
    "# year_colnm : 연도 컬럼명\n",
    "# test_year : test년도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파일명 / 해당 파일의 target 컬럼들 (target명으로 합치고 싶은 순서대로 기입) / 파일마다의 y 컬럼명 / 연도 컬럼명 / test년도 입력\n",
    "data_folder = 'data'\n",
    "save_folder = 'result'\n",
    "file_nm = ['merge_age_new','merge_cls_new','merge_dis_new','merge_part_age','merge_part_dis9']\n",
    "target = [['SIDO','SCHOOL_TP'],['SIDO'],['SIDO','DIS_TYPE'],['SIDO_EDU_NM','PART_EDU_NM','PART_EDU_CD','SCHOOL_TP'],['PART_EDU_NM','PART_EDU_CD']]\n",
    "y_colnm = ['SEP_CNT','SEP_CNT','SEP_CNT','SEP_CNT','SEP_CNT']\n",
    "year_colnm = ['BASE_YY','BASE_YY','BASE_YY','BASE_YY','BASE_YY']\n",
    "test_year = ['2021','2021','2021','2021','2021']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 독립변수(x)에 대하여 표준화 진행 시 원하는 표준화 기법 선택 (입력 안하면 표준화 진행 X)\n",
    "# 1 : 표준화1(StandardScaler) : 평균 = 0 / 표준편차 = 1\n",
    "# 2 : 표준화2(Normalization) : MinMaxScaler : 최소값 0 ~ 최대값 1 \n",
    "# 3 : 표준화3(RobustScaler) : 중앙값 = 0 / IQR(1분위(25%) ~ 3분위(75%)) = 1 \n",
    "select_scaler = 1  # (1, 2, 3) 중 택 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 2. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 정보 통합\n",
    "file_info = pd.DataFrame(file_nm).rename(columns = {0:'file_nm'})\n",
    "file_info['target'] = target\n",
    "file_info['y_colnm'] = y_colnm\n",
    "file_info['year_colnm'] = year_colnm\n",
    "file_info['test_year'] = test_year\n",
    "\n",
    "# h2o 호출\n",
    "h2o.init(nthreads=1)\n",
    "\n",
    "for file_num in range(len(file_info)):\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------------------------ #\n",
    "    # 분석 정보 호출\n",
    "    file_nm = file_info['file_nm'][file_num]\n",
    "    target = file_info['target'][file_num]\n",
    "    y_colnm = file_info['y_colnm'][file_num]\n",
    "    year_colnm = file_info['year_colnm'][file_num]\n",
    "    test_year = file_info['test_year'][file_num]\n",
    "\n",
    "    # 데이터 호출\n",
    "    tot_data = pd.read_csv(data_folder + '/' + file_nm + '.csv', dtype='str', encoding = 'cp949')\n",
    "    tot_data.rename(columns = {year_colnm:'YEAR'}, inplace=True)  # 연도 컬럼명 변경\n",
    "    \n",
    "    # train 연도 정의 (위에서 정의한 test년도 제외)\n",
    "    train_year = list(tot_data['YEAR'].unique())\n",
    "    train_year.remove(test_year)\n",
    "    # ------------------------------------------------------------------------------------------------------------------ #\n",
    "    # target 리스트를 병합하여 하나의 컬럼('target')으로 생성 (ex. 강원,특수교육 => 강원_특수교육)\n",
    "    for trg_num in range(len(target)):\n",
    "        if len(target) == 1:\n",
    "            tot_data['target'] = tot_data[target[trg_num]]\n",
    "        else:\n",
    "            if trg_num == 0:\n",
    "                tot_data['target'] = tot_data[target[trg_num]]\n",
    "            else:\n",
    "                tot_data['target'] = tot_data['target'] + '_' + tot_data[target[trg_num]]\n",
    "    # ------------------------------------------------------------------------------------------------------------------ #\n",
    "    ## 데이터 구분\n",
    "    # 월 데이터\n",
    "    if file_nm.find('month') != -1:\n",
    "        tot_data['STAND_TIME'] = tot_data['YEAR'] + tot_data['MONTH']\n",
    "        except_colnm = ['YEAR','MONTH','STAND_TIME']\n",
    "    # 분기 데이터\n",
    "    elif file_nm.find('quarter') != -1:\n",
    "        tot_data['STAND_TIME'] = tot_data['YEAR'] + tot_data['QUARTER']\n",
    "        except_colnm = ['YEAR','QUARTER','STAND_TIME']\n",
    "    # 반기 데이터\n",
    "    elif file_nm.find('half') != -1:\n",
    "        tot_data['STAND_TIME'] = tot_data['YEAR'] + tot_data['HALF']\n",
    "        except_colnm = ['YEAR','HALF','STAND_TIME']\n",
    "    # 연 데이터\n",
    "    else:\n",
    "        tot_data['STAND_TIME'] = tot_data['YEAR']  # YEAR 컬럼 생성\n",
    "        except_colnm = ['YEAR','STAND_TIME']\n",
    "    # ------------------------------------------------------------------------------------------------------------------ #\n",
    "    # 독립변수 컬럼명 정의 : x_colnm\n",
    "    tot_colnm = list(tot_data.columns)                                 # 전체 컬럼명\n",
    "    except_colnm = ([y_colnm] + target + ['target'] + except_colnm)    # 독립변수에서 제외할 컬럼명\n",
    "    x_colnm = list(set(tot_colnm).difference(set(except_colnm)))       # 독립변수 컬럼명\n",
    "\n",
    "    # tot_data 재정의 : 필요 컬럼만 추출\n",
    "    tot_data = tot_data[['STAND_TIME','YEAR','target'] + [y_colnm] + x_colnm]\n",
    "    # ------------------------------------------------------------------------------------------------------------------ #\n",
    "    ## 모델 생성 start\n",
    "    \n",
    "    # loop_target : 타겟 리스트 : 소단위 모델 생성\n",
    "    loop_target = list(tot_data['target'])  \n",
    "    for trg in loop_target:\n",
    "\n",
    "        print(trg)\n",
    "\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        # 분석 수행 데이터 정의\n",
    "        data = tot_data.loc[tot_data['target'] == trg,].sort_values(by = 'STAND_TIME').reset_index(drop=True)\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        # 데이터 형 변환(str -> float)\n",
    "        for chg_col in ([y_colnm] + x_colnm):\n",
    "            data[chg_col] = data[chg_col].astype('float')\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        # (train / test) 데이터 분할\n",
    "        train = data.loc[data['YEAR'].isin(train_year),[y_colnm] + x_colnm]\n",
    "        test = data.loc[~data['YEAR'].isin(train_year),[y_colnm] + x_colnm]\n",
    "\n",
    "        # (train_x / train_y / test_x / test_y) 데이터 분할\n",
    "        train_x = train[x_colnm].reset_index(drop=True)\n",
    "        train_y = train[[y_colnm]].reset_index(drop=True)\n",
    "        test_x = test[x_colnm].reset_index(drop=True)\n",
    "        test_y = test[[y_colnm]].reset_index(drop=True)\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        ## 표준화 수행\n",
    "        \n",
    "        # StandardScaler : 평균 0, 표준편차 1\n",
    "        if select_scaler == 1:\n",
    "            from sklearn.preprocessing import StandardScaler\n",
    "            scaler = StandardScaler()   \n",
    "            mody_train_x = pd.DataFrame(scaler.fit_transform(train_x), columns = list(train_x.columns))\n",
    "            mody_test_x = pd.DataFrame(scaler.transform(test_x), columns = list(test_x.columns))\n",
    "        \n",
    "        # Normalization : MinMaxScaler : 최소값 0 ~ 최대값 1\n",
    "        elif select_scaler == 2:\n",
    "            from sklearn.preprocessing import MinMaxScaler\n",
    "            scaler = MinMaxScaler()\n",
    "            mody_train_x = pd.DataFrame(scaler.fit_transform(train_x), columns = list(train_x.columns))\n",
    "            mody_test_x = pd.DataFrame(scaler.transform(test_x), columns = list(test_x.columns))\n",
    "\n",
    "        # RobustScaler : 중앙값 0, IQR(1분위(25%) ~ 3분위(75%)) 1 : 이상치(outlier) 영향 최소화 / 더 넓게 분포\n",
    "        elif select_scaler == 3:\n",
    "            from sklearn.preprocessing import RobustScaler\n",
    "            scaler = RobustScaler()\n",
    "            mody_train_x = pd.DataFrame(scaler.fit_transform(train_x), columns = list(train_x.columns))\n",
    "            mody_test_x = pd.DataFrame(scaler.transform(test_x), columns = list(test_x.columns))\n",
    "        \n",
    "        else:\n",
    "            mody_train_x = train_x\n",
    "            mody_test_x = test_x\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        # 모델에 사용할 train, test 데이터셋\n",
    "        mdl_train_data = pd.concat([train_y, mody_train_x], axis = 1)\n",
    "        mdl_test_data = mody_test_x\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        ## 독립변수 선택\n",
    "\n",
    "        # 1. 상관분석 : 상관분석은 train 데이터만 이용 (test 데이터 이용 X)\n",
    "        corr_data = pd.concat([train_y,mody_train_x], axis = 1)\n",
    "        corr = corr_data.corr(method = 'pearson')  # default는 'pearson'\n",
    "        corr = corr.reset_index().rename(columns = {'index':'COLNM'})\n",
    "        corr = corr.loc[corr['COLNM'] != y_colnm,]\n",
    "        corr = corr[corr[y_colnm] >= 0.5]\n",
    "\n",
    "        # 2. 상관분석 결과로 선택된 독립변수 목록\n",
    "        mdl_x_colnm = list(corr['COLNM'])\n",
    "\n",
    "        # 3. 독립변수 목록 중 null값이 없는 독립변수만 선택\n",
    "        train_na_col = []\n",
    "        for col in mdl_test_data.columns:\n",
    "            if len(mdl_train_data.loc[mdl_train_data[col].isna(),]) != 0:\n",
    "                train_na_col.append(col)\n",
    "\n",
    "        test_na_col = []\n",
    "        for col in mdl_test_data.columns:\n",
    "            if len(mdl_test_data.loc[mdl_test_data[col].isna(),]) != 0:\n",
    "                test_na_col.append(col)\n",
    "\n",
    "        tot_na_col = list(set(train_na_col + test_na_col))  # null값이 있는 독립변수들\n",
    "        mdl_x_colnm = list(set(mdl_x_colnm).difference(set(tot_na_col)))  # 모델에 사용할 독립변수들\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        # h2o 데이터프레임 형식으로 변환\n",
    "        h2o_train_data = h2o.H2OFrame(mdl_train_data)\n",
    "        h2o_test_data = h2o.H2OFrame(mdl_test_data)\n",
    "\n",
    "        ## 모델 생성\n",
    "        model = H2OAutoML(max_models=20, max_runtime_secs=10, seed=1234)\n",
    "        model.train(x = mdl_x_colnm, y = y_colnm,\n",
    "                    training_frame = h2o_train_data)  # x : 독립변수 / y : 종속변수 / training_frame : 학습데이터 / 모델 검증은 pass\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        # # View the AutoML Leaderboard\n",
    "        # lb = model.leaderboard\n",
    "        # lb.head(rows = 10)  # 가장 성능 좋은 모델 top 10개 확인\n",
    "        # model.leader  # 리더보드 값 확인 : The leader model is stored here\n",
    "\n",
    "        # ## 모델 조사\n",
    "        # m = model.leader  # Get the best model using the metric\n",
    "        # m = model.get_best_model()  # this is equivalent to\n",
    "\n",
    "        ## AutoML 출력\n",
    "        # Get leaderboard with all possible columns\n",
    "        lb = h2o.automl.get_leaderboard(model, extra_columns = \"ALL\")  # lb : top 10개 모델에 대한 리더보드 확인\n",
    "        save_lb = lb.as_data_frame()  # pandas 데이터프레임으로 형변환\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        ## 예측 수행\n",
    "        pred = model.predict(h2o_test_data)\n",
    "\n",
    "        ## h2o 데이터프레임을 pandas 데이터프레임으로 변환\n",
    "        pred = h2o.as_list(pred, use_pandas=True)  # 또는 pred.as_data_frame()\n",
    "        pred.rename(columns={'predict':'PREDICT'}, inplace=True)\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "#         ## h2o 종료\n",
    "#         h2o.cluster().shutdown()\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        ## 결과값 정리\n",
    "        rslt = pd.concat([pred, test_y], axis = 1)\n",
    "        rslt['target'] = trg\n",
    "        rslt['stand_time'] = list(data.loc[~data['YEAR'].isin(train_year),'STAND_TIME'])\n",
    "        rslt['BEST_MDL'] = save_lb['model_id'][0]\n",
    "        rslt['DIFF'] = rslt['PREDICT'] - rslt['SEP_CNT']\n",
    "        rslt['mdl_x_colnm'] = str(mdl_x_colnm)\n",
    "\n",
    "        rslt['PREDICT'] = round(rslt['PREDICT'],4)\n",
    "        rslt['SEP_CNT'] = round(rslt['SEP_CNT'],4)\n",
    "        rslt['DIFF'] = round(rslt['DIFF'],4)\n",
    "        \n",
    "        rslt = rslt[['target', 'stand_time', 'PREDICT', 'SEP_CNT', 'DIFF', 'BEST_MDL']]\n",
    "        # -------------------------------------------------------------------------------------------------------------- #\n",
    "        ## 결과값 저장\n",
    "        if trg == loop_target[0]:\n",
    "            fin_result = rslt\n",
    "        else:\n",
    "            fin_result = fin_result.append(rslt)\n",
    "\n",
    "    fin_result.to_csv(save_folder + '/result_' + file_nm + '.csv', index=False, encoding = 'utf-8')\n",
    "\n",
    "# h2o 종료\n",
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('총 모델 생성 시간 : ', time.time() - total_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AutoML 설명\n",
    "# (1) AutoML은 총 20여 개의 머신러닝과 딥러닝 모델을 포함한 알고리즘임\n",
    "# (2) 학습 시 해당 데이터에 가장 적합한 모델을 선택하며, 파라미터 또한 최적화 된 값을 선택해줌\n",
    "# (3) AutoML은 머신러닝 기반의 모형이기 때문에, 통계적 모형인 회귀 모형과는 달리 다중공선성 등의 변수 선택 과정을 진행하지 않음\n",
    "\n",
    "## AutoML 변수 선택 과정(모델 개발 시 적용)\n",
    "# (1) 독립변수에 대해 표준화\n",
    "# - StandardScaler : 평균은 0, 표준편차는 1로 변환\n",
    "# - Normalization : 최소값을 0, 최대값을 1로 변환 (0~1 사이의 값으로 변환)\n",
    "# - RobustScaler : 중앙값을 0, IQR(1분위수~3분위수)을 1로 변환 : 이상치의 영향 최소화\n",
    "# (2) 상관분석\n",
    "# - 상관계수의 기준을 0.5 이상으로 잡아서 최대한 적용되지 않는 독립변수의 수를 줄임\n",
    "# (3) Null 값이 포함된 변수 제외\n",
    "# - 독립변수 중 특정 연도의 값이 Null 값인 경우, 해당 변수를 독립변수에서 제외\n",
    "\n",
    "## 결과 해석\n",
    "# - AutoML을 이용하여 (월/분기/반기/연) 모형을 개발해 본 결과, (시도별*연령별 / 시도별*학급(학교)별 / 시도별*장애영역별) 모형 모두 MSE 값이 가장 작은 모델로 ‘연 모형’이 채택되었음\n",
    "# - AutoML은 20여 개의 모델이 포함된 알고리즘이므로, 각 단위 별로 20여 개의 모델을 이용하여 (월/분기/반기/연) 모형을 테스트 해봤다고 할 수 있음\n",
    "# - 따라서, 각 단위 별 연 MSE 값이 가장 낮은 모델로 ‘연 모델'이 가장 많이 선택되었으므로 해당 데이터를 이용한 모델링은 ‘연 모델’이 적합하다고 판단됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
